{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gwSczy5qUtJK",
        "outputId": "4e42e14a-7992-4434-8f47-523c624cbd1d"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VK5fn5ayWOW0",
        "outputId": "a74dd95c-e0d2-450e-f11f-d2788601d3f2"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T9QgULR8dNUx",
        "outputId": "cdafbdc8-a315-4709-de13-dfd3441f1dcb"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2Ry-l5oxiJ7W",
        "outputId": "9665abbf-6545-43e9-e48a-14aac01cbf82"
      },
      "outputs": [],
      "source": [
        "pip install Sastrawi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PuOLC663WPk1",
        "outputId": "d2d4f342-734c-4201-d647-4289a94cff94"
      },
      "outputs": [],
      "source": [
        "pip install pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wz0aif1NWRAR",
        "outputId": "c6ca931e-098a-4b8c-a85b-64d83d95fcfa"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYVNcnkjr7b"
      },
      "source": [
        "# Simpan File di Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glhxLCsYd6mN",
        "outputId": "9118cc18-e3aa-453b-b44f-200d1377b459"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFrXj2Qnejxu"
      },
      "outputs": [],
      "source": [
        "# Create a folder in the root directory\n",
        "!mkdir -p \"/content/drive/My Drive/OCR Data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIB5_myXfTLj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def mount_drive():\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "def save_to_drive(source_path, target_path):\n",
        "    if not os.path.isdir('/content/drive'):\n",
        "        mount_drive()\n",
        "\n",
        "    if os.path.isfile(source_path):\n",
        "        shutil.copy(source_path, target_path)\n",
        "        print(f\"File '{source_path}' has been copied to '{target_path}'.\")\n",
        "    elif os.path.isdir(source_path):\n",
        "        shutil.copytree(source_path, target_path)\n",
        "        print(f\"Directory '{source_path}' has been copied to '{target_path}'.\")\n",
        "    else:\n",
        "        print(f\"Source path '{source_path}' does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-56h8BPfZjA",
        "outputId": "b31faa06-14c5-4c06-a045-a450cfd3dfea"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "mount_drive()\n",
        "\n",
        "# Save a single file to Google Drive\n",
        "# save_to_drive('/content/cv_data.csv', '/content/drive/My Drive/OCR Data/cv_data.csv')\n",
        "\n",
        "# Save an entire directory to Google Drive\n",
        "# save_to_drive('/content/clean_images', '/content/drive/My Drive/OCR Data/clean_images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQsseHO8j3Fp"
      },
      "source": [
        "# Simpan File di Lokal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrdSSVlzh6Ei"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def download_from_colab(source_path):\n",
        "    if os.path.isfile(source_path):\n",
        "        files.download(source_path)\n",
        "        print(f\"File '{source_path}' is being downloaded.\")\n",
        "    elif os.path.isdir(source_path):\n",
        "        zip_path = source_path + '.zip'\n",
        "        shutil.make_archive(source_path, 'zip', source_path)\n",
        "        files.download(zip_path)\n",
        "        print(f\"Directory '{source_path}' is being downloaded as '{zip_path}'.\")\n",
        "    else:\n",
        "        print(f\"Source path '{source_path}' does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "L758bKwKh9Ak",
        "outputId": "0be26639-500d-496c-998c-7030c538390e"
      },
      "outputs": [],
      "source": [
        "# Download a single file\n",
        "download_from_colab('/content/cv_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzrde08piEQx",
        "outputId": "849032d3-931c-47b0-a276-74c3976d8bc6"
      },
      "outputs": [],
      "source": [
        "# Download an entire directory\n",
        "download_from_colab('/content/clean_images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8cPabupWXG8"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iorr8kNNWSl9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCqz0juJC_Zq"
      },
      "source": [
        "# Remove Folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gHR09f9DBJr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlHCZIgt3U8W"
      },
      "outputs": [],
      "source": [
        "def remove_folder(folder_path):\n",
        "    if os.path.exists(folder_path):\n",
        "        shutil.rmtree(folder_path)\n",
        "        print(f'Folder {folder_path} berhasil dihapus.')\n",
        "    else:\n",
        "        print(f'Folder {folder_path} tidak ditemukan.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-K88Gx93VZ5",
        "outputId": "f95c9feb-bf3d-4127-fc3f-15339b03f9f7"
      },
      "outputs": [],
      "source": [
        "# Contoh pemanggilan fungsi\n",
        "folder_path = '/content/cv_raw_data'\n",
        "remove_folder(folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BznrGVLeTMj"
      },
      "source": [
        "# Upload File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiB7neBfW1sA"
      },
      "outputs": [],
      "source": [
        "def upload_and_save_file(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f'Direktori {directory} berhasil dibuat.')\n",
        "\n",
        "    uploaded = files.upload()\n",
        "    for filename, file_content in uploaded.items():\n",
        "        full_path = os.path.join(directory, filename)\n",
        "        with open(full_path, 'wb') as f:\n",
        "            f.write(file_content)\n",
        "\n",
        "        print(f'File {filename} berhasil disimpan di {full_path}.')\n",
        "\n",
        "    # Hapus file yang secara otomatis disimpan di direktori Colab\n",
        "    for filename in uploaded.keys():\n",
        "        os.remove(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "collapsed": true,
        "id": "EkaMsk7NcQYr",
        "outputId": "4a22355c-af42-45af-dd81-140fd1cd83b6"
      },
      "outputs": [],
      "source": [
        "upload_and_save_file('/content/cv_raw_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7ojk4nbiQGO"
      },
      "source": [
        "# Convert pdf to image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8CFtC3JiOhJ"
      },
      "outputs": [],
      "source": [
        "def convert_pdf_to_images(input_dir, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith('.pdf'):\n",
        "            pdf_path = os.path.join(input_dir, filename)\n",
        "            images = convert_from_path(pdf_path)\n",
        "            pdf_name = os.path.splitext(filename)[0]\n",
        "            pdf_output_dir = os.path.join(output_dir, pdf_name)\n",
        "            if not os.path.exists(pdf_output_dir):\n",
        "                os.makedirs(pdf_output_dir)\n",
        "            for i, image in enumerate(images):\n",
        "                image_path = os.path.join(pdf_output_dir, f'{pdf_name}_page_{i + 1}.jpg')\n",
        "                image.save(image_path, 'JPEG')\n",
        "                print(f'Page {i + 1} dari file {filename} berhasil dikonversi dan disimpan di {image_path}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zkeJppxOlHfo"
      },
      "outputs": [],
      "source": [
        "convert_pdf_to_images('/content/drive/MyDrive/cv-raw-data', '/content/drive/MyDrive/cv_images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTTj2CKllUt1"
      },
      "source": [
        "# Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtAP5bSAlYFm"
      },
      "outputs": [],
      "source": [
        "def image_preprocessing(img_path, cv_name, output_dir):\n",
        "    # Load image\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    # Rescaling the image\n",
        "    img = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Converting image to grayscale\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Applying dilation and erosion to remove noise\n",
        "    kernel = np.ones((1, 1), np.uint8)\n",
        "    img = cv2.dilate(img, kernel, iterations=1)\n",
        "    img = cv2.erode(img, kernel, iterations=1)\n",
        "\n",
        "    # Applying blur\n",
        "    img = cv2.medianBlur(img, 3)\n",
        "\n",
        "    # Thresholding\n",
        "    img = cv2.threshold(img, 65, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    # Create CV directory if not exists\n",
        "    cv_dir = os.path.join(output_dir, cv_name)\n",
        "    if not os.path.exists(cv_dir):\n",
        "        os.makedirs(cv_dir)\n",
        "\n",
        "    # Save processed image\n",
        "    image_name = os.path.splitext(os.path.basename(img_path))[0] + '_processed.jpg'\n",
        "    output_path = os.path.join(cv_dir, image_name)\n",
        "    cv2.imwrite(output_path, img)\n",
        "\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ovzCzaJ2w6z"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk memproses semua gambar CV dalam direktori input dan menyimpan hasilnya ke direktori output\n",
        "def process_cv_images(input_dir, output_dir):\n",
        "    output_clean_images_dir = os.path.join(output_dir, 'clean_images')\n",
        "    if not os.path.exists(output_clean_images_dir):\n",
        "        os.makedirs(output_clean_images_dir)\n",
        "\n",
        "    for cv_name in os.listdir(input_dir):\n",
        "        cv_dir = os.path.join(input_dir, cv_name)\n",
        "        if os.path.isdir(cv_dir):\n",
        "            for filename in os.listdir(cv_dir):\n",
        "                if filename.endswith('.jpg'):\n",
        "                    image_path = os.path.join(cv_dir, filename)\n",
        "                    processed_image_path = image_preprocessing(image_path, cv_name, output_clean_images_dir)\n",
        "                    print(f'Image {filename} dari CV {cv_name} telah diproses dan disimpan di {processed_image_path}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knLdj8H12zxi",
        "outputId": "2905f0f2-10c6-4437-ab7e-decfde198cd7"
      },
      "outputs": [],
      "source": [
        "output_dir = '/content'\n",
        "process_cv_images('/content/drive/MyDrive/cv_images', output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47NzWnMw5npa"
      },
      "source": [
        "# Extract text from image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfGhGHf45tq5"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_image(image_path):\n",
        "    # Load preprocessed image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Extract text using Tesseract OCR\n",
        "    extracted_text = pytesseract.image_to_string(img)\n",
        "\n",
        "    return extracted_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rpHIx1W5u6z"
      },
      "outputs": [],
      "source": [
        "def process_images_to_dataframe(input_dir):\n",
        "    data = []\n",
        "    for cv_name in os.listdir(input_dir):\n",
        "        print('a')\n",
        "        cv_dir = os.path.join(input_dir, cv_name)\n",
        "        if os.path.isdir(cv_dir):\n",
        "            cv_text = \"\"\n",
        "            for filename in os.listdir(cv_dir):\n",
        "                if filename.endswith('_processed.jpg'):\n",
        "                    image_path = os.path.join(cv_dir, filename)\n",
        "                    text = extract_text_from_image(image_path)\n",
        "                    cv_text += text + \"\\n\\n\"  # Gabungkan teks dari setiap halaman\n",
        "            data.append({'CV Name': cv_name, 'Text': cv_text})\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HW0VTdQ5yj1",
        "outputId": "d09c02c3-f815-43aa-c456-729c7b759700"
      },
      "outputs": [],
      "source": [
        "input_dir = '/content/drive/MyDrive/clean_images'\n",
        "df = process_images_to_dataframe(input_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "collapsed": true,
        "id": "-q13CdwH6Vxx",
        "outputId": "20d0eec4-82d8-43e3-88ee-c4a2c1be180c"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drsCfSrZe9xB"
      },
      "source": [
        "# Simpan Data dalam CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0ntmkX7e2VK"
      },
      "outputs": [],
      "source": [
        "def dataframe_to_csv(df, output_dir, filename):\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f'DataFrame berhasil disimpan sebagai CSV di: {output_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2eNsYVSfJZz",
        "outputId": "f0e7a029-4bc5-4c26-b153-fe647d046d14"
      },
      "outputs": [],
      "source": [
        "output_dir = '/content'\n",
        "filename = 'cv_data.csv'\n",
        "dataframe_to_csv(df, output_dir, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9R3ql0ueA5J"
      },
      "source": [
        "# Persebaran Kata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyY83YofeI8N"
      },
      "outputs": [],
      "source": [
        "def create_word_cloud(df, text_column):\n",
        "    # Gabungkan semua teks dalam kolom text_column menjadi satu string\n",
        "    text = ' '.join(df[text_column].tolist())\n",
        "\n",
        "    # Buat word cloud\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "    # Tampilkan word cloud\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "3-KBbtRIgCVp",
        "outputId": "65256f80-b09a-4e6d-e202-23389d21013c"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/cv_data.csv')\n",
        "create_word_cloud(df, 'Text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld1glhmUgKoW"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK_cUkbSieoP",
        "outputId": "58ad9ba6-8efe-482f-a8bf-e2357246b266"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcDc34b0iiFz"
      },
      "outputs": [],
      "source": [
        "stopwords_english = set(stopwords.words('english'))\n",
        "stopwords_indonesian = set(stopwords.words('indonesian'))\n",
        "all_stopwords = stopwords_english.union(stopwords_indonesian) # gabung stopwords dari english dan indonesian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxDpbJsuirHM"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer() # ubah ke bentuk dasar (english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIYPLqwOityW"
      },
      "outputs": [],
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer() # ubah ke bentuk dasar (indonesian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe-uOHYqi1hu"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    print('a')\n",
        "    # Remove extra spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "   # Remove stopwords for English and lemmatize\n",
        "    if stopwords_english:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(token) for token in tokens if token.lower() not in stopwords_english]\n",
        "\n",
        "    # Remove stopwords for Indonesian\n",
        "    if stopwords_indonesian:\n",
        "        tokens = [token for token in tokens if token.lower() not in stopwords_indonesian]\n",
        "        # Stem the tokens for Indonesian\n",
        "        tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    # Remove extra spaces or lines\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "\n",
        "    return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bJBu-3OtqphU",
        "outputId": "3134083b-f3f9-463c-f064-97e088fd0924"
      },
      "outputs": [],
      "source": [
        "df['Preprocessed_Text'] = df['Text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONtuQqzFyebr"
      },
      "outputs": [],
      "source": [
        "df['Preprocessed_Text'].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe_tBr50tXyf"
      },
      "outputs": [],
      "source": [
        "create_word_cloud(df, 'Preprocessed_Text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTHzTJ9MAXdX",
        "outputId": "dc27ca0a-b60b-46dd-f5f4-b79fafdfec8d"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ask7syHmAqNE"
      },
      "outputs": [],
      "source": [
        "sp_sm = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o-UsqZcAq5v",
        "outputId": "eb2dc8a2-6c94-4480-e7ea-576029915db9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "# import pytesseract # OCR library\n",
        "import spacy\n",
        "# Process with spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(df.iloc[0]['Text'])\n",
        "\n",
        "# Extract entities\n",
        "entities = []\n",
        "for ent in doc.ents:\n",
        "    entities.append((ent.text, ent.label_))\n",
        "    print(ent.text, ent.label_)\n",
        "    logging.info(f\"{ent.text} : {ent.label_}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vdYVNcnkjr7b"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
